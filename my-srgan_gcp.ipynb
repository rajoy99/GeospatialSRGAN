{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00007-a07396e6-1e09-413b-a070-c9f2fcbdd72a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 861,
    "execution_start": 1623001749111,
    "source_hash": "ec8bbc54"
   },
   "outputs": [],
   "source": [
    "# Importing all the necessary modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU\n",
    "from tensorflow.keras.layers import add\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "f = BytesIO(file_io.read_file_to_string(\"gs://ucsb_data/lowres.npy\", binary_mode=True))\n",
    "arr = np.load(f)\n",
    "type(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00008-ca0e6d17-f29e-48ec-ae48-4efaad46d28c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1623001749980,
    "source_hash": "21fde94e"
   },
   "outputs": [],
   "source": [
    "# Residual block\n",
    "def res_block_gen(model, kernal_size, filters, strides):\n",
    "    \n",
    "    gen = model\n",
    "    \n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    # Using Parametric ReLU\n",
    "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "        \n",
    "    model = add([gen, model])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00009-d7da6d67-f98a-4699-a956-ec796ca157ad",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1623001749988,
    "source_hash": "b263c22e"
   },
   "outputs": [],
   "source": [
    "def up_sampling_block(model, kernal_size, filters, strides):\n",
    "    '''\n",
    "    In place of Conv2D and UpSampling2D we can also use Conv2DTranspose (Both are used for Deconvolution)\n",
    "    Even we can have our own function for deconvolution\n",
    "    model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    '''\n",
    "    \n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = UpSampling2D(size = 2)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00010-3eb03abe-4260-4b1d-8ea3-c7a3d67b97a3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1623001749993,
    "source_hash": "c4521821"
   },
   "outputs": [],
   "source": [
    "def discriminator_block(model, filters, kernel_size, strides):\n",
    "    \n",
    "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00012-f1e338dc-2c6c-49a8-8b5d-7e717697d146",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1623001750005,
    "source_hash": "743e8fe"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Generator(object):\n",
    "\n",
    "    def __init__(self, noise_shape):\n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "\n",
    "    def generator(self):\n",
    "        \n",
    "        gen_input = Input(shape = self.noise_shape)\n",
    "\n",
    "        model = Conv2D(filters = 16, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
    "        model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
    "\n",
    "        gen_model = model\n",
    "\n",
    "        # Using 16 Residual Blocks\n",
    "        for index in range(16):\n",
    "            model = res_block_gen(model, 3, 16, 1)\n",
    "\n",
    "        model = Conv2D(filters = 16, kernel_size = 3, strides = 1, padding = \"same\")(model)\n",
    "        model = BatchNormalization(momentum = 0.5)(model)\n",
    "        model = add([gen_model, model])\n",
    "\n",
    "        # Using 2 UpSampling Blocks\n",
    "        for index in range(2):\n",
    "            model = up_sampling_block(model, 3, 64, 1)\n",
    "\n",
    "        model = Conv2D(filters = 1, kernel_size = 9, strides = 1, padding = \"same\")(model)\n",
    "        model = Activation('tanh')(model)\n",
    "\n",
    "        generator_model = Model(inputs = gen_input, outputs = model)\n",
    "\n",
    "        return generator_model\n",
    "    \n",
    "image_shape = (64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00014-013e0a49-8cb9-4a55-af05-112360bb9b0d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1623001750057,
    "source_hash": "6677a819"
   },
   "outputs": [],
   "source": [
    "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
    "class Discriminator(object):\n",
    "\n",
    "    def __init__(self, image_shape):\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "    \n",
    "    def discriminator(self):\n",
    "        \n",
    "        dis_input = Input(shape = self.image_shape)\n",
    "        \n",
    "        model = Conv2D(filters = 16, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
    "        model = LeakyReLU(alpha = 0.2)(model)\n",
    "        \n",
    "        model = discriminator_block(model, 8, 3, 2)\n",
    "        model = discriminator_block(model, 16, 3, 1)\n",
    "        model = discriminator_block(model, 16, 3, 2)\n",
    "        model = discriminator_block(model, 32, 3, 1)\n",
    "        model = discriminator_block(model, 32, 3, 2)\n",
    "        model = discriminator_block(model, 64, 3, 1)\n",
    "        model = discriminator_block(model, 64, 3, 2)\n",
    "        \n",
    "        model = Flatten()(model)\n",
    "        model = Dense(64)(model)\n",
    "        model = LeakyReLU(alpha = 0.2)(model)\n",
    "       \n",
    "        model = Dense(1)(model)\n",
    "        model = Activation('sigmoid')(model) \n",
    "        \n",
    "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
    "        return discriminator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00015-73c048dc-d72e-4343-a1be-f6ef0087cc35",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1623001750058,
    "source_hash": "f418e44c"
   },
   "outputs": [],
   "source": [
    "def get_gan_network(discriminator, shape, generator, optimizer):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=shape)\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs=gan_input, outputs=[x,gan_output])\n",
    "    gan.compile(loss=[\"binary_crossentropy\", \"binary_crossentropy\"],\n",
    "                loss_weights=[1., 1e-3],\n",
    "                optimizer=optimizer)\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00022-3f12891e-9591-47e4-943a-abb666730f49",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 44,
    "execution_start": 1623001750058,
    "source_hash": "338611d8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#loading the lowres data ⬇️\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "f = BytesIO(file_io.read_file_to_string(\"gs://ucsb_data/lowres.npy\", binary_mode=True))\n",
    "X=np.load(f)\n",
    "\n",
    "# Finding out where are nan values. Returns boolean array of same size\n",
    "\n",
    "whnan=np.isnan(X)\n",
    "whnan\n",
    "X[whnan]=-1\n",
    "X_train,X_test=X[:10000,:,:],X[-4300:,:,:]\n",
    "\n",
    "#loading the highres data  ⬇️\n",
    "f = BytesIO(file_io.read_file_to_string(\"gs://ucsb_data/highres.npy\", binary_mode=True))\n",
    "Y=np.load(f)\n",
    "whnan=np.isnan(Y)\n",
    "whnan\n",
    "Y[whnan]=-1\n",
    "Y_train,Y_test=Y[:10000,:,:],Y[-4300:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 64, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00024-942d0830-0246-40ea-95f8-a1346a2d8a23",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1623001750102,
    "source_hash": "d69df3e8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 400.\n",
    "X_test = X_test.astype('float32') / 400.\n",
    "Y_train = Y_train.astype('float32') / 400.\n",
    "Y_test = Y_test.astype('float32') / 400.\n",
    "# add 1 extra dimension so single input vector looks like [[[]]]\n",
    "x_train_lr_new = np.reshape(X_train, (len(X_train), 16, 16, 1))\n",
    "x_test_lr_new = np.reshape(X_test, (len(X_test), 16, 16, 1))\n",
    "x_train_hr_new = np.reshape(Y_train, (len(Y_train), 64, 64, 1))\n",
    "x_test_hr_new = np.reshape(Y_test, (len(Y_test), 64, 64, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00054-7a319e4e-911f-432e-b2c3-1802dc4bb694",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 53,
    "execution_start": 1623001750140,
    "source_hash": "b4760864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16, 16, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lr_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00057-c1bc56f7-0e2e-46a5-9b91-3ddccbba7ce9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1623001750141,
    "source_hash": "67c72a70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 64, 64, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_hr_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00063-eafc9f64-ceb2-47b6-b56c-c9386949a547",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 51,
    "execution_start": 1623001750142,
    "source_hash": "d562f64e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4300, 64, 64, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_hr_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00066-81b67516-08eb-43f7-8f21-1427b5afdf9c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42,
    "execution_start": 1623001750151,
    "source_hash": "d411df4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4300, 16, 16, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_lr_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "00071-650b5328-4362-44d4-827c-0b5d1b517367",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1623001750161,
    "source_hash": "e7cae1d1"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "00079-b25583f1-d64d-4d9c-848f-b9abaa647e9b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3841,
    "execution_start": 1623001750242,
    "source_hash": "4b05222e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-29 14:57:28.232622: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-29 14:57:28.251683: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000095000 Hz\n",
      "2021-09-29 14:57:28.252790: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556f674cf6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-29 14:57:28.252824: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-09-29 14:57:28.255049: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "epochs=100 # epochs = 20000\n",
    "batch_size=64\n",
    "\n",
    "downscale_factor = 4\n",
    "    \n",
    "batch_count = int(x_train_hr_new.shape[0] / batch_size)\n",
    "shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
    "generator = Generator(shape).generator()\n",
    "discriminator = Discriminator(image_shape).discriminator()\n",
    "\n",
    "adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "generator.compile(loss=\"binary_crossentropy\", optimizer=adam)\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=adam)\n",
    "\n",
    "shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, 1)\n",
    "gan = get_gan_network(discriminator, shape, generator, adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "cell_id": "00082-3caa357f-6e9a-47ce-b63f-599fa4d9cc09",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 865808,
    "execution_start": 1623001754091,
    "source_hash": "59b23ff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 1 ---------------\n",
      "Loss HR , Loss LR, Loss GAN\n",
      "0.3457344174385071 0.3604010343551636 [0.07615480571985245, 0.07437014579772949, 1.7846577167510986]\n",
      "--------------- Epoch 2 ---------------\n"
     ]
    }
   ],
   "source": [
    "hr_loss, lr_loss, gan_loss = [], [], []\n",
    "m1, m2, m3 = [], [], []\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "    for i in range(batch_count):\n",
    "        rand_nums = np.random.randint(0, x_train_hr_new.shape[0], size=batch_size)\n",
    "\n",
    "        image_batch_hr =  np.stack(x_train_hr_new[rand_nums], axis=0)\n",
    "        image_batch_lr = np.stack(x_train_lr_new[rand_nums], axis=0)\n",
    "            \n",
    "        generated_images_sr = generator.predict(image_batch_lr)\n",
    "\n",
    "        real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "        fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
    "\n",
    "        discriminator.trainable = True\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
    "        #d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "        rand_nums = np.random.randint(0, x_train_hr_new.shape[0], size=batch_size)\n",
    "    \n",
    "        image_batch_hr =  np.stack(x_train_hr_new[rand_nums], axis=0)\n",
    "        image_batch_lr = np.stack(x_train_lr_new[rand_nums], axis=0)\n",
    "\n",
    "        gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "\n",
    "        discriminator.trainable = False\n",
    "        loss_gan = gan.train_on_batch(image_batch_lr, [image_batch_hr,gan_Y])\n",
    "\n",
    "    print(\"Loss HR , Loss LR, Loss GAN\")\n",
    "    print(d_loss_real, d_loss_fake, loss_gan)\n",
    "    \n",
    "    hr_loss.append(d_loss_real)\n",
    "    lr_loss.append(d_loss_fake)\n",
    "    gan_loss.append(loss_gan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# rand_nums = np.random.randint(0, x_train_hr_new.shape[0], size=2)\n",
    "rand_nums=[23]\n",
    "image_batch_hr =  np.stack(x_train_hr_new[rand_nums], axis=0)\n",
    "image_batch_lr = np.stack(x_train_lr_new[rand_nums], axis=0)\n",
    "            \n",
    "generated_images_sr = generator.predict(image_batch_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig, ax = plt.subplots(nrows=1, ncols=3,figsize=(15,15))\n",
    "    \n",
    "\n",
    "    ax[0].imshow(image_batch_lr[0])\n",
    "    ax[0].title.set_text('Low Res')\n",
    "    \n",
    "    ax[1].imshow(generated_images_sr[0])\n",
    "    ax[1].title.set_text('Generated Super Resution')\n",
    "    \n",
    "    ax[2].imshow(image_batch_hr[0])\n",
    "    ax[2].title.set_text('Ground Truth (High Res)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_loss_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gan_loss)\n",
    "\n",
    "for a in gan_loss:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(gan_loss)\n",
    "print(np.mean(gan_loss))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
