{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fe018cfcc422d825bcb95dbfc5bdcb8375fa9baec5cbc0535c3d8fa1380d2765"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D, PReLU,BatchNormalization, Flatten\n",
    "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ip = Input(shape=(25,25,3))\n",
    "hr_ip = Input(shape=(100,100,3))train_lr,train_hr = #training images arrays normalized between 0 & 1\n",
    "test_lr, test_hr = # testing images arrays normalized between 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-d3b4b7233547>, line 20)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d3b4b7233547>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    return up_modelnum_res_block = 16# Generator Model\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Residual block\n",
    "def res_block(ip):\n",
    "    \n",
    "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
    "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
    "    res_model = PReLU(shared_axes = [1,2])(res_model)\n",
    "    \n",
    "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
    "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
    "    \n",
    "    return add([ip,res_model])# Upscale the image 2x\n",
    "\n",
    "\n",
    "def upscale_block(ip):\n",
    "    \n",
    "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
    "    up_model = UpSampling2D( size = 2 )(up_model)\n",
    "    up_model = PReLU(shared_axes=[1,2])(up_model)\n",
    "    \n",
    "    return up_modelnum_res_block = 16 # Generator Model\n",
    "\n",
    "\n",
    "\n",
    "def create_gen(gen_ip):\n",
    "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
    "    layers = PReLU(shared_axes=[1,2])(layers)    temp = layers    for i in range(num_res_block):\n",
    "        layers = res_block(layers)    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
    "    layers = BatchNormalization(momentum=0.5)(layers)\n",
    "    layers = add([layers,temp])    layers = upscale_block(layers)\n",
    "    layers = upscale_block(layers)    op = Conv2D(3, (9,9), padding=\"same\")(layers)    \n",
    "    return Model(inputs=gen_ip, outputs=op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small block inside the discriminator\n",
    "def discriminator_block(ip, filters, strides=1, bn=True):\n",
    "    \n",
    "    disc_model = Conv2D(filters, (3,3), strides, padding=\"same\")(ip)\n",
    "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
    "    if bn:\n",
    "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)    \n",
    "        \n",
    "    return disc_model# Discriminator Model\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def create_disc(disc_ip):\n",
    "    df = 64\n",
    "    \n",
    "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
    "    d2 = discriminator_block(d1, df, strides=2)\n",
    "    d3 = discriminator_block(d2, df*2)\n",
    "    d4 = discriminator_block(d3, df*2, strides=2)\n",
    "    d5 = discriminator_block(d4, df*4)\n",
    "    d6 = discriminator_block(d5, df*4, strides=2)\n",
    "    d7 = discriminator_block(d6, df*8)\n",
    "    d8 = discriminator_block(d7, df*8, strides=2)\n",
    "    \n",
    "    d8_5 = Flatten()(d8)\n",
    "    d9 = Dense(df*16)(d8_5)\n",
    "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "    validity = Dense(1, activation='sigmoid')(d10)    return Model(disc_ip, validity)"
   ]
  },
  {
   "source": [
    "<b>VGG 19 Model </b>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG19# Build the VGG19 model upto 10th layer \n",
    "# Used to extract the features of high res imgaes\n",
    "def build_vgg():    \n",
    "    vgg = VGG19(weights=\"imagenet\")\n",
    "    vgg.outputs = [vgg.layers[9].output]    img = Input(shape=hr_shape)\n",
    "    img_features = vgg(img)    return Model(img, img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):    gen_img = gen_model(lr_ip)\n",
    "    gen_features = vgg(gen_img)\n",
    "    disc_model.trainable = False\n",
    "    validity = disc_model(gen_img)    return Model([lr_ip, hr_ip],[validity,gen_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_gen(lr_ip)\n",
    "discriminator = create_disc(hr_ip)\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",      \n",
    "  metrics=['accuracy'])vgg = build_vgg()\n",
    "vgg.trainable = Falsegan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)\n",
    "gan_model.compile(loss=[\"binary_crossentropy\",\"mse\"], loss_weights=\n",
    "  [1e-3, 1], optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_lr_batches = []\n",
    "train_hr_batches = []\n",
    "for it in range(int(train_hr.shape[0] / batch_size)):\n",
    "    start_idx = it * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    train_hr_batches.append(train_hr[start_idx:end_idx])\n",
    "    train_lr_batches.append(train_lr[start_idx:end_idx])train_lr_batches = np.array(train_lr_batches)\n",
    "train_hr_batches = np.array(train_hr_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for e in range(epochs):\n",
    "    gen_label = np.zeros((batch_size, 1))\n",
    "    real_label = np.ones((batch_size,1))\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    for b in range(len(train_hr_batches)):\n",
    "        lr_imgs = train_lr_batches[b]\n",
    "        hr_imgs = train_hr_batches[b]\n",
    "        gen_imgs = generator.predict_on_batch(lr_imgs)        #Dont forget to make the discriminator trainable\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        #Train the discriminator\n",
    "        d_loss_gen = discriminator.train_on_batch(gen_imgs,\n",
    "          gen_label)\n",
    "        d_loss_real = discriminator.train_on_batch(hr_imgs,\n",
    "          real_label)\n",
    "        discriminator.trainable = False        \n",
    "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)        \n",
    "        image_features = vgg.predict(hr_imgs)\n",
    "        \n",
    "        #Train the generator\n",
    "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], \n",
    "          [real_label, image_features])\n",
    "        \n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "    g_losses = np.array(g_losses)\n",
    "    d_losses = np.array(d_losses)\n",
    "    \n",
    "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
    "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)    \n",
    "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.ones((len(test_lr),1))\n",
    "test_features = vgg.predict(test_hr)eval,_,_ = gan_model.evaluate([test_lr, test_hr], [label,test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = generator.predict_on_batch(test_lr)"
   ]
  }
 ]
}